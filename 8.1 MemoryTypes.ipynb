{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1596b0c-3159-4283-a7f9-5b5606ce491f",
   "metadata": {},
   "source": [
    "# ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "002a1284-d6d5-4a79-bf13-d8d1327b263a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p8/_23vf8_97jn_kt805y1dkmmr0000gn/T/ipykernel_48512/3317147136.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='My name is Terry', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you Terry', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Where is Seoul?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Seoul is in Korea', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# k is number of interaction\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    k=2, memory_key=\"chat_history\", return_messages=True\n",
    ")\n",
    "memory.clear()\n",
    "memory.save_context(\n",
    "    {\"input\": \"Hello chatbot!\"}, {\"output\": \"Hello. How can I help you?\"}\n",
    ")\n",
    "memory.save_context({\"input\": \"My name is Terry\"}, {\"output\": \"Nice to meet you Terry\"})\n",
    "memory.save_context({\"input\": \"Where is Seoul?\"}, {\"output\": \"Seoul is in Korea\"})\n",
    "\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0aa7dc-95a5-4ed3-8882-4fa639605285",
   "metadata": {},
   "source": [
    "# Conversation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4140e860-01ae-49cb-9b52-070321c6423c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p8/_23vf8_97jn_kt805y1dkmmr0000gn/T/ipykernel_48512/2119252634.py:8: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(llm=model, return_messages=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [SystemMessage(content='The human greets the chatbot, and the AI responds by asking how it can help.', additional_kwargs={}, response_metadata={})]}\n",
      "{'history': [SystemMessage(content='The human greets the chatbot, and the AI responds by asking how it can help. The human introduces himself as Terry, and the AI replies that it is nice to meet him.', additional_kwargs={}, response_metadata={})]}\n",
      "{'history': [SystemMessage(content='The human greets the chatbot, and the AI responds by asking how it can help. The human introduces himself as Terry, and the AI replies that it is nice to meet him. Terry then asks where Seoul is, and the AI informs him that Seoul is in Korea.', additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory.summary import ConversationSummaryMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "model = ChatOpenAI(api_key=\"{YOUR_OPENAI_KEY}\", temperature=0)\n",
    "\n",
    "# k is number of interaction\n",
    "memory = ConversationSummaryMemory(llm=model, return_messages=True)\n",
    "memory.clear()\n",
    "memory.save_context(\n",
    "    {\"input\": \"Hello chatbot!\"}, {\"output\": \"Hello. How can I help you?\"}\n",
    ")\n",
    "print(memory.load_memory_variables({}))\n",
    "memory.save_context({\"input\": \"My name is Terry\"}, {\"output\": \"Nice to meet you Terry\"})\n",
    "print(memory.load_memory_variables({}))\n",
    "memory.save_context({\"input\": \"Where is Seoul?\"}, {\"output\": \"Seoul is in Korea\"})\n",
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f0c4f9-636c-48b6-8886-4d9fede7f39a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conversation Summary Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44796fb9-3d3f-4997-90e4-62255a23b8a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human greets the chatbot, and the AI responds by asking how it can help. The human introduces himself as Terry, and the AI replies that it is nice to meet him.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Where is Seoul?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Seoul is in Korea', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory.summary_buffer import ConversationSummaryBufferMemory\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "\n",
    "# model = OpenAI(openai_api_key=\"{YOUR_OPENAI_KEY}\", temperature=0)\n",
    "\n",
    "# k is number of interaction\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=model, return_messages=True, max_token_limit=20\n",
    ")\n",
    "memory.clear()\n",
    "memory.save_context(\n",
    "    {\"input\": \"Hello chatbot!\"}, {\"output\": \"Hello. How can I help you?\"}\n",
    ")\n",
    "memory.save_context({\"input\": \"My name is Terry\"}, {\"output\": \"Nice to meet you Terry\"})\n",
    "memory.save_context({\"input\": \"Where is Seoul?\"}, {\"output\": \"Seoul is in Korea\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
